<!DOCTYPE html>
<!-- saved from url=(0034)https://raymin0223.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Sangmin Bae</title>
<meta content="Sangmin Bae" name="Sangmin Bae">
<link href="./Sangmin_Bae_files/style.css" rel="stylesheet" type="text/css">
<script src="./Sangmin_Bae_files/jquery-1.11.1.min.js" type="text/javascript"></script>  
</head>


<body>
  <div class="menu"> <a href="https://www.raymin0223.com/index.html">Home</a>  <a href="https://www.raymin0223.com/index.html#publications">Publications</a>  
	  <a href="https://www.raymin0223.com/index.html#patents"> Patents</a>  <a href="https://www.raymin0223.com/index.html#awards"> Awards</a> 
	  <a href="https://www.raymin0223.com/index.html#projects">Projects</a> <a href="https://www.raymin0223.com/index.html#experience"> Experience</a>  
	  <a href="https://www.raymin0223.com/index.html#services"> Services</a> 
  </div>
  <div class="container">
    <table border="0">
      <tbody><tr>
        <td><img src="./Sangmin_Bae_files/bio-ray.jpg" width="130"></td>
        <td style="width: 10px">&nbsp;</td>
        <td valign="top" width="500">
          <span class="name">Sangmin Bae</span>
          <p class="information"><br>
           Research Scientist, <a href="http://osi.kaist.ac.kr/">OSI Lab</a> </p>
          <p class="information">Graduate School of AI, KAIST<br>
            85 Hoegi-ro, Dongdaemun-gu, Seoul, Korea<br></p>
          <p class="information"><strong>Email</strong>: <span class="unselectable">bsmn0223<span class="mock"></span><span class="hide">xkxkxk</span>@kaist.ac.kr</span> <span class="unselectable">/ bsmn0223<span class="mock"></span><span class="hide">xkxkxk</span>@gmail.com</span> </br>
	  <a href="https://drive.google.com/drive/folders/1CBpE2SYBjA9cOm8vblU8gZyugeCkvHvf?usp=share_link">CV</a>, <a href="http://www.linkedin.com/in/raymin0223/">Linkedin</a>, <a href="https://twitter.com/raymin0223">Twitter</a>, <a href="https://github.com/raymin0223/">Github</a> </p>
        </td>
      </tr>
    </tbody></table>
  <strong>Welcome to my page!</strong> I am a Research Scientist with a strong desire to become a  <strong>versatile T-shaped expert in AI</strong>. While I have primarily focused on <br>Computer Vision, I have also explored other AI domains, including NLP, Audio, Tabular, and Video, to broaden my knowledge and expertise. </p>
   My research interests lie in <strong>Efficient AI</strong>, which entails exploring training- or data-efficient approaches to make AI more accessible and sustainable. <br>Some of my research areas include Self-Supervised Learning, Federated Learning, Generative AI, and Multimodal Learning.
   <!-- I am a Research Scientist at the Amazon Transcribe Team of AWS AI Labs. Previsouly, I was Research Scientist at NAVER AI Lab in 2021-2022. I also graduated with my PhD in February 2021 from the Graduate School of Knowledge Service Engineering (currently, Data Science) at KAIST and worked as a research intern at Google Research, where I was fortunate to work with two supervisors, <a href="https://scholar.google.com/citations?user=h9mbv9MAAAAJ&hl=en&oi=ao"><font color="#000080">Prof. Jae-Gil Lee</font></a> and <a href="https://scholar.google.com/citations?hl=en&user=p9-ohHsAAAAJ"><font color="#000080">Prof. Ming-Hsuan Yang</font></a>. My current research interests lie in exploring the cutting-edge technologies for future AI (e.g., Data Robust/Efficient Learning, Transformers, Large Language Models) and improving the performance of AI systems under real-world scenarios related to data scale and quality. -->


   <a id="news" class="anchor"></a><span class="section">News</span>    
    
    <p class="news">
     <strong>May. 2024:</strong>  &#x1F38A A paper on 'Hard Prompt Optimization with RL' accepted at ACL 2024.
    </p>
    <p class="news">
     <strong>Apr. 2024:</strong>  &#x1F38A A paper on 'Respiratory Sound Classification' accepted at EMBC 2024.
    </p>
    <p class="news">
     <strong>Mar. 2024:</strong>  &#x1F38A A Long paper on 'Evolving Questions-Answering Benchamrk' accepted at NAACL 2024.
    </p>
    <p class="news">
    <strong>Jan. 2024:</strong> &#x1F948 Silver Award from Samsung Humantech Paper Awards.
    </p>
    <p class="news">
     <strong>Dec. 2023:</strong>  &#x1F38A A paper on 'Cross-domain Adaptation on Respiratory Sound' accepted at ICASSP 2024.
    </p>

    <p>&nbsp;</p>

   <a id="education" class="anchor"></a><span class="section">Education</span> 

   <li style="line-height:160%;"> Ph.D. student in Graduate School of AI, KAIST. Advised by Prof. <a href="https://scholar.google.com/citations?user=X_IAjb8AAAAJ&hl=en"><font color="#000080">Se-Young Yun</font></a>. &nbsp;&nbsp;<em>Mar. 2021 - Present</em> </li> 
   <li style="line-height:160%;">  M.S. in Industrial and Systems Engineering, KAIST. Advised by Prof. Se-Young Yun. &nbsp;&nbsp;<em>Mar. 2019 - Feb. 2021</em> </li> 
   <li style="line-height:160%;">  B.S. in Industrial and Systems Engineering. &nbsp;&nbsp;<em>Mar. 2014 - Feb. 2019</em> </li> 
	

   <p>&nbsp;</p>

    <!-- Publication session -->
    <a id="publications" class="anchor"></a><span class="section">Publications <a href="https://scholar.google.com/citations?user=T5rHY14AAAAJ&hl=en">  Google Scholar </a> </span>
    *: 1st co-authors, <sup>&dagger;</sup>: corresponding authors, C: conferences, J: journals, W: workshops, P: preprints </br> </br>
    <table border="0" width="90%" class="paper">
	
	</tbody></table></br>
	<font size="4.5px"><strong>2024</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
	
        <tr>
          <td>
            <img src="./images/2024_axa.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            [P3] Sungnyun Kim*, Kangwook Jang*, <strong>Sangmin Bae</strong>, Hoirin Kim<sup>&dagger;</sup>, Se-Young Yun<sup>&dagger;</sup>. <strong>Learning Video Temporal Dynamics with Asymmetric Cross-Modal Attention for Robust Audio-Visual Speech Recognition</strong>. <em>Preprint</em> 2024.
          </td>
        </tr> 
		
        <tr>
          <td>
            <img src="./images/2024_pin.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            [C10] Yunseon Choi, <strong>Sangmin Bae</strong>, Seonghyun Ban, Minchan Jeong, Chuheng Zhang, Lei Song, Li Zhao, Jiang Bian, Kee-Eung Kim<sup>&dagger;</sup>. <strong>Hard Prompts Made Interpretable: Sparse Entropy Regularization for Prompt Tuning with RL</strong>. <em>The Association for Computational Linguistics</em> (ACL) 2024.
          </td>
        </tr>  
		
        <tr>
          <td>
            <img src="./images/2024_repaugment.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            [C9] June-Woo Kim, Miika Toikkanen, <strong>Sangmin Bae</strong>, Minseok Kim<sup>&dagger;</sup>, Ho-Young Jung<sup>&dagger;</sup>.  <strong>RepAugment: Input-Agnostic Representation-Level Augmentation for Respiratory Sound Classification</strong>. <em>International Conference of the IEEE Engineering in Medicine and Biology Society</em> (EMBC) 2024.
          </td>
        </tr>  

	
        <tr>
          <td>
            <img src="./images/2023_carpe_diem.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            [C8] Yujin Kim, Jaehong Yoon, Seonghyeon Ye, <strong>Sangmin Bae</strong>, Namgyu Ho, Sung Ju Hwang<sup>&dagger;</sup>, Se-Young Yun<sup>&dagger;</sup>.  <strong>Carpe diem: On the Evaluation of World Knowledge in Lifelong Language Models</strong>. <em>Conference of the North American Chapter of the Association for Computational Linguistics</em> (NAACL) Long Paper 2024.
            [<a href="https://github.com/kimyuji/EvolvingQA_benchmark"><font color="#000080">code</font></a>]
	  </td>
        </tr>  
		
        <tr>
          <td>
            <img src="./images/2023_sg_scl.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            [C7] June-Woo Kim, <strong>Sangmin Bae</strong>, Won-Yang Cho, Byungjo Lee, Ho-Young Jung<sup>&dagger;</sup>.  <strong>Stethoscope-guided Supervised Contrastive Learning for Cross-domain Adaptation on Respiratory Sound Classification</strong>. <em>IEEE International Conference on Acoustics, Speech and Signal Processing</em> (ICASSP) 2024.
	    [<a href="https://arxiv.org/pdf/2312.09603.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/kaen2891/stethoscope-guided_supervised_contrastive_learning"><font color="#000080">code</font></a>]
          </td>
        </tr>   
	    
	</tbody></table></br>
	<font size="4.5px"><strong>2023</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
		
        <tr>
          <td>
            <img src="./images/2023_adversarial_ft.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            [W6] June-Woo Kim, Chihyeon Yoon, Miika Toikkanen, <strong>Sangmin Bae</strong>, Ho-Young Jung<sup>&dagger;</sup>.  <strong>Adversarial Fine-tuning using Generated Respiratory Sound to Address Class Imbalance</strong>. <em>Neural Information Processing Systems Workshop on Deep Generative Models for Health</em> (NeurIPSW) 2023.
            [<a href="https://arxiv.org/pdf/2311.06480.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/kaen2891/adversarial_fine-tuning_using_generated_respiratory_sound"><font color="#000080">code</font></a>]
	  </td>
        </tr>   
	      
        <tr>
          <td>
            <img src="./images/2023_tabular_retrieval.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            [W5] Felix den Breejen, <strong>Sangmin Bae</strong>, Stephen Cha, Tae-Young Kim, Seoung-Hyun Koh, Se-Young Yun<sup>&dagger;</sup>.  <strong>Exploring the Retrieval Mechanism for Tabular Deep Learning</strong>. <em>Neural Information Processing Systems Workshop on Table Representation Learning</em> (NeurIPSW) 2023.
            [<a href="https://arxiv.org/pdf/2311.07343.pdf"><font color="#000080">pdf</font></a>]
	  </td>
        </tr>   

        <tr>
          <td>
            <img src="./images/2023_free.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            [C6] <strong>Sangmin Bae</strong>*, Jongwoo Ko*, Hwanjun Song<sup>&dagger;</sup>, Se-Young Yun<sup>&dagger;</sup>.  <strong>Fast and Robust Early-Exiting Framework for Autoregressive Language Models with Synchronized Parallel Decoding</strong>. <em>Conference on Empirical Methods in Natural Language Processing</em> (EMNLP) Long Paper 2023.            
 	    [<a href="https://arxiv.org/pdf/2310.05424.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/raymin0223/fast_robust_early_exit"><font color="#000080">code</font></a>]
          </td>
        </tr>   

        <tr>
          <td>
            <img src="./images/2023_patchmix.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td bgcolor="#e9eaed">
            [C5] <strong>Sangmin Bae</strong>*, June-Woo Kim*, Won-Yang Cho, Hyerim Baek, Soyoun Son, Byungjo Lee, Changwan Ha, Kyongpil Tae, Sungnyun Kim<sup>&dagger;</sup>, Se-Young Yun<sup>&dagger;</sup>.  <strong>Patch-Mix Contrastive Learning with Audio Spectrogram Transformer on Respiratory Sound Classification</strong>. <em>Conference of the International Speech Communication Association </em>  (INTERSPEECH) 2023.
            [<a href="https://arxiv.org/pdf/2305.14032.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/raymin0223/patch-mix_contrastive_learning"><font color="#000080">code</font></a>]
          </td>
        </tr>   

        <tr>
          <td>
            <img src="./images/2023_openset.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            [C4] Sungnyun Kim*, <strong>Sangmin Bae</strong>*, Se-Young Yun<sup>&dagger;</sup>.   <strong>Coreset Sampling from Open-Set for Fine-Grained Self-Supervised Learning</strong>. <em>International Conference on Computer Vision and Pattern Recognition </em>  (CVPR) 2023.
            [<a href="https://arxiv.org/pdf/2303.11101.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/sungnyun/openssl-simcore"><font color="#000080">code</font></a>]
          </td>
        </tr>   

        <tr>
        <td>
            <img src="./images/2023_logo.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td bgcolor="#e9eaed">
            [C3] Sangmook Kim*, <strong>Sangmin Bae</strong>*, Hwanjun Song<sup>&dagger;</sup>, Se-Young Yun<sup>&dagger;</sup>.  <strong>Re-thinking Federated Active Learning based on Inter-class Diversity</strong>. <em>International Conference on Computer Vision and Pattern Recognition </em> (CVPR) 2023. 
            [<a href="https://arxiv.org/pdf/2303.12317.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/raymin0223/LoGo"><font color="#000080">code</font></a>]
          </td>
        </tr>    

        <tr>
        <td>
            <img src="./images/2023_selfcon.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            [C2] <strong>Sangmin Bae</strong>*, Sungnyun Kim*, Jongwoo Ko, Gihun Lee, Seungjong Noh, Se-Young Yun<sup>&dagger;</sup>.  <strong>Self-Contrastive Learning: Single-viewed Supervised Contrastive Framework using Sub-network</strong>. <em>The Association for the Advancement of Artificial Intelligence </em> (AAAI) 2023. <span class="oral">Oral Presentation.</span>
            [<a href="https://arxiv.org/pdf/2106.15499.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/raymin0223/self-contrastive-learning"><font color="#000080">code</font></a>]
          </td>
        </tr>  
	  
	  
	</tbody></table></br>
	<font size="4.5px"><strong>2022</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
	   
      <tr>
        <td>
          <img src="./images/2022_fedntd.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td bgcolor="#e9eaed">
          [C1] Gihun Lee*, Minchan Jeong*, Yongjin Shin, <strong>Sangmin Bae</strong>, Se-Young Yun<sup>&dagger;</sup>. <strong>Preservation of Global Knowledge by Not-True Distillation in Federated Learning</strong>. <em>Neural Information Processing Systems </em> (NeurIPS) 2022. 
		  [<a href="https://arxiv.org/pdf/2106.03097.pdf"><font color="#000080">pdf</font></a>]
		  [<a href="https://github.com/Lee-Gihun/FedNTD"><font color="#000080">code</font></a>]
		  </td>
      </tr>
	  	  

      <tr>
        <td>
          <img src="./images/2022_openset.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td>
          [W4] Sungnyun Kim*, <strong>Sangmin Bae</strong>*, Se-Young Yun<sup>&dagger;</sup>. <strong>Coreset Sampling from Open-Set for Fine-Grained Self-Supervised Learning</strong>. <em>Neural Information Processing Systems Workshop on Self-Supervised Learning: Theory and Practice</em> (NeurIPSW) 2022. 
		  [<a href="https://sslneurips22.github.io/paper_pdfs/paper_28.pdf"><font color="#000080">pdf</font></a>]
		  </td>
      </tr>

      <tr>
        <td>
          <img src="./images/2022_lg_fal.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td bgcolor="#e9eaed">
          [W3] Sangmook Kim*, <strong>Sangmin Bae</strong>*, Hwanjun Song<sup>&dagger;</sup>, Se-Young Yun<sup>&dagger;</sup>.  <strong>LG-FAL: Federated Active Learning Strategy using Local and Global Models</strong>. <em>International Conference on Machine Learning Workshop on daptive Experimental Design and Active Learning in the Real World </em> (ICMLW) 2022. 
          [<a href="https://realworldml.github.io/files/cr/paper46.pdf"><font color="#000080">pdf</font></a>]
        </td>
      </tr>  
      
	</tbody></table></br>
	<font size="4.5px"><strong>2020</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
	  
        <tr>
        <td>
          <img src="./images/2020_mixco.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td>
          [W2] Sungnyun Kim*, Gihun Lee*, <strong>Sangmin Bae</strong>*, Se-Young Yun<sup>&dagger;</sup>.  <strong>MixCo: Mix-up Contrastive Learning for Visual Representation</strong>. <em>Neural Information Processing Systems Workshop on Self-Supervised Learning: Theory and Practice </em> (NeurIPSW) 2020. 
          [<a href="https://arxiv.org/pdf/2010.06300.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/Lee-Gihun/MixCo-Mixup-Contrast"><font color="#000080">code</font></a>]
        </td>
      </tr>   

      <tr>
        <td>
          <img src="./images/2020_mabfl.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td bgcolor="#e9eaed">
          [P1] Taehyeon Kim*, <strong>Sangmin Bae</strong>*, Jin-woo Lee, Se-Young Yun<sup>&dagger;</sup>.  <strong>Accurate and Fast Federated Learning via Combinatorial Multi-Armed Bandits</strong>. <em>Preprint </em> 2020. 
          [<a href="https://arxiv.org/pdf/2012.03270.pdf"><font color="#000080">pdf</font></a>]
        </td>
      </tr>   

        <tr>
        <td>
          <img src="./images/2020_sipa.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td>
          [W1] Gihun Lee*, <strong>Sangmin Bae</strong>*, Jaehoon Oh, Se-Young Yun<sup>&dagger;</sup>.  <strong>SIPA: A Simple Framework for Efficient Networks</strong>. <em>IEEE International Conference on Data Mining Workshop on Big Data Analysis for Smart Engergy </em> (ICDMW) 2020. 
          [<a href="https://arxiv.org/pdf/2004.14476.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/Lee-Gihun/MicroNet_OSI-AI"><font color="#000080">code</font></a>]
        </td>
      </tr>   
	  
    </tbody></table>

    <p>&nbsp;</p>
	 
    <a id="patents" class="anchor"></a><span class="section">Patents</span>
    <li style="line-height:130%;"> Se-Young Yun, Seongyoon Kim, Woojin Chung, <strong>Sangmin Bae</strong>. Toward Enhanced Representation for Federated Re-Identification by Not-True Self <br>Knowledge Distillation. Korea Patent Application. &nbsp;&nbsp;<em>Aug. 2022</em></li>
    <li style="line-height:130%;"> Jaehoon Oh, Sangmook Kim, Se-Young Yun, <strong>Sangmin Bae</strong>, Jaewoo Shin, Seongyoon Kim, Woojin Chung. Federated Learning System for Performing Individual Data Customized Federated Learning, Method for Federated Learning, and Client Aratus for Performing Same. Korea and US Patent Application. <br><em>Jun. 2022, Oct. 2022</em></li>
    <li style="line-height:130%;"> Gihun Lee, Minchan Jeong, Se-Young Yun, <strong>Sangmin Bae</strong>, Jaeyeon Ahn, Seongyoon Kim, Woojin Chung. System, Method, Computer-Readable Storage Medium and Computer Program for Federated Learning of Local Model based on Learning Direction of Global Model. Korea and US Patent Application. <br><em>Jun. 2022, Oct. 2022</em></li>	
    
    <p>&nbsp;</p>

	 
    <a id="awards" class="anchor"></a><span class="section">Awards and Honors</span>
    <li style="line-height:160%;">  Silver Award in Signal Processing from Samsung Humantech Paper Awards. &nbsp;&nbsp;<em>Jan. 2024</em> </li>
    <li style="line-height:160%;">  Two Best Presentation Awards from Korea Computing Congress (KCC). &nbsp;&nbsp;<em>Aug. 2022</em> </li>
    <li style="line-height:160%;">  Best Paper Award (5th Place) from Korean AI Association and LG AI Research (JKAIA). &nbsp;&nbsp;<em>Nov. 2021</em></li>
    <li style="line-height:160%;">    <a href="https://micronet-challenge.github.io"><font color="#000080">MicroNet Challenge</font></a> 4th Place at NeurIPS Workshop. &nbsp;&nbsp;<em>Oct. 2019</em> </li>
    <li style="line-height:160%;"> Alumni Scholarship from KAIST. &nbsp;&nbsp;<em>Mar. 2017 - Feb. 2019</em> </li>
    <li style="line-height:160%;"> Dean's List (Top 3%) at Faculty of Engineering Department in KAIST. &nbsp;&nbsp;<em>Spring 2017</em> </li>
    
    <p>&nbsp;</p>

	 
    <a id="projects" class="anchor"></a><span class="section">Research Projects</span>

    
    <li style="line-height:160%;"> [<strong>NIER</strong>] Short-term Prediction of Particulate Matter via Artificial Intelligence. <span class="oral">Project Manager</span>. &nbsp;&nbsp;<em>Mar. 2023 - Present</em>  </li> 
    <li style="line-height:160%;">  [<strong>KT</strong>] Neural Architecture Search for Detecting Communication Network Failure. <span class="oral">Project Manager</span>. &nbsp;&nbsp;<em>Apr. 2022 - Feb. 2023</em>   </li> 
    <li style="line-height:160%;">  [<strong>ETRI</strong>] Lightweight Edge Device Technology via Federated Learning. <span class="oral">Project Manager</span>. &nbsp;&nbsp;<em>Mar. 2021 - Sep. 2022</em>  </li> 
    <li style="line-height:160%;"> [<strong>SK Hynix</strong>] Semantic Segmentation to Detect Errors in Wafer Process. &nbsp;&nbsp;<em>Feb. 2021 - Sep. 2021</em>  </li>  
    <li style="line-height:160%;"> [<strong>ETRI</strong>] Data-efficient Unsupervised Representation Learning. &nbsp;&nbsp;<em>Mar. 2020 - Dec. 2020</em>  </li> 
    <li style="line-height:160%;"> [<strong>ETRI</strong>] Model Compression for Big Data Ddge Analysis. &nbsp;&nbsp;<em>Jun. 2019 - Oct. 2019</em>  </li>
    <li style="line-height:160%;"> [<strong>Hankook Tire and Technology</strong>] Compound Prediction with Artificial Intelligence and Auto-ML. &nbsp;&nbsp;<em>Mar. 2019 - Feb. 2020</em>  </li>

    <p>&nbsp;</p>

	 
    <a id="experience" class="anchor"></a><span class="section">Research Experience</span>
    <li style="line-height:160%;">  Research Collaboration with MODULABS. &nbsp;&nbsp;<em>Sep. 2022 - Jan. 2024</em> </li>
    <li style="line-height:160%;">  Research Collaboration with NAVER AI, advised by <a href="https://scholar.google.com/citations?user=Ijzuc-8AAAAJ&hl=en"><font color="#000080">Hwanjun Song</font></a>. &nbsp;&nbsp;<em>Jan. 2022 - Jan. 2023</em> </li>
    <li style="line-height:160%;">  Research Internship at Kakao Recommendation Team. &nbsp;&nbsp;<em>Sep. 2018 - Feb. 2019</em> </li>
    <li style="line-height:160%;">   Research Internship at Optimization and Statistical Inference Lab, KAIST. &nbsp;&nbsp;<em>Jul. 2018 - Aug. 2018</em> </li>
    <li style="line-height:160%;">  Research Internship at Human Factors and Ergonomics Lab, KAIST. &nbsp;&nbsp;<em>Dec. 2017 - Jun. 2018</em> </li>
    <li style="line-height:160%;">   Exchange Student at  Link√∂ping University, Sweden. &nbsp;&nbsp;<em>Jul. 2017 - Aug. 2017</em>    </li>

    <p>&nbsp;</p>
	 
    <a id="services" class="anchor"></a><span class="section">Services</span>
    <li style="line-height:160%;">  Server Manager at KAIST AI. &nbsp;&nbsp;<em>Mar. 2021 - Feb. 2023</em> </li>
    <li style="line-height:160%;">  Student Leader at OSI Lab, KAIST. &nbsp;&nbsp;<em>Mar. 2021 - Mar. 2022</em></li>
    <li style="line-height:160%;">  Teaching Assistant. </li>
	<ul>
		<li style="line-height:160%; margin-left: 10px; list-style-type: none;">&minus; KAIST AI505 Optimization for AI. &nbsp;&nbsp;<em>Fall 2021, Fall 2022, Fall 2023</em> </li>
		<li style="line-height:160%; margin-left: 10px; list-style-type: none;">&minus; KAIST AI603 Machine Learning Theory . &nbsp;&nbsp;<em>Spring 2021, Spring 2023</em> </li>
		<li style="line-height:160%; margin-left: 10px; list-style-type: none;">&minus; KAIST AI611 Deep Reinforcement Learning. &nbsp;&nbsp;<em>Spring 2022</em> </li>
	</ul>
    <li style="line-height:160%;"> Instructor on DL and ML courses. </li>
    <ul>
	    <li style="line-height:160%; margin-left: 10px; list-style-type: none;">&minus; MetaCode: Machine Learning Course. [<a href="https://www.youtube.com/watch?v=oyzIT1g1Z3U&t=0s"><font color="#000080">video</font></a>] (views 110K) &nbsp;&nbsp;<em>Jun. 2021 - Dec. 2022</em> </li>
	    <li style="line-height:160%; margin-left: 10px; list-style-type: none;">&minus; ForumM: Recommendation Seminar. &nbsp;&nbsp;<em>Nov. 2022</em> </li>
	    <li style="line-height:160%; margin-left: 10px; list-style-type: none;">&minus; LG-KAIST AI: Computer Vision Course. &nbsp;&nbsp;<em>Oct. 2020, Oct. 2021</em> </li>
	    <li style="line-height:160%; margin-left: 10px; list-style-type: none;">&minus; Korea Blockchain Institute: Machine Learning Course. &nbsp;&nbsp;<em>Dec. 2020</em> </li>
	    <li style="line-height:160%; margin-left: 10px; list-style-type: none;">&minus; Samsung DS: Deep Learning Course. &nbsp;&nbsp;<em>Jul. 2020</em> </li>
    </ul>
    
    </br>  

  <p><font color="#444444" face="Arial" size="2">&copy 2023 Sangmin Bae Thanks <a href="https://songhwanjun.github.io"><font color="#000080">Dr. Hwanjun Song</font></a> for the template. </font></p>

  </div>
  <script>
    var thumbnails = document.getElementsByClassName("PaperThumbnail");
    var i;
    for (i = 0; i < thumbnails.length; i++) {
      thumbnails[i].width = "120"
    }
  </script>  


</body></html>
