<!DOCTYPE html>
<!-- saved from url=(0034)https://raymin0223.github.io/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Sangmin Bae</title>
<meta content="Sangmin Bae" name="Sangmin Bae">
<link href="./Sangmin_Bae_files/style.css" rel="stylesheet" type="text/css">
<script src="./Sangmin_Bae_files/jquery-1.11.1.min.js" type="text/javascript"></script>  
</head>


<body>
  <div class="menu"> <a href="https://raymin0223.github.io/index.html">Home</a>  <a href="https://raymin0223.github.io/index.html#publications">Publications</a>  
    <a href="https://raymin0223.github.io/index.html#projects">Projects</a> <a href="https://raymin0223.github.io/index.html#services"> Services</a>   <a href="https://raymin0223.github.io/index.html#awards"> Awards</a> 
    <a href="https://raymin0223.github.io/index.html#patents"> Patents</a> 
  </div>
  <div class="container">
    <table border="0">
      <tbody><tr>
        <td><img src="./Sangmin_Bae_files/bio-ray.jpg" width="130"></td>
        <td style="width: 10px">&nbsp;</td>
        <td valign="top" width="500">
          <span class="name">Sangmin Bae</span>
          <p class="information"><br>
           Research Scientist, <a href="http://osi.kaist.ac.kr/">OSI Lab</a> </p>
          <p class="information">Graduate School of AI, KAIST<br>
            85 Hoegi-ro, Dongdaemun-gu, Seoul, Korea<br></p>
          <p class="information"><strong>Email</strong>: <span class="unselectable">bsmn0223<span class="mock"></span><span class="hide">xkxkxk</span>@kaist.ac.kr</span> <span class="unselectable">/ bsmn0223<span class="mock"></span><span class="hide">xkxkxk</span>@gmail.com</span> </br>
	  <a href="http://www.linkedin.com/in/raymin0223/">Linkedin</a>, <a href="http://https://twitter.com/raymin0223">Twitter</a>, <a href="https://github.com/raymin0223/">Github</a> </p>
        </td>
      </tr>
    </tbody></table>
  <strong>Welcome to my page!</strong> I am a Research Scientist with a strong desire to become a  <strong>versatile T-shaped expert in AI</strong>. While I have primarily focused on Computer Vision, I have also explored other AI domains, including NLP, Tabular, Audio, and Video, to broaden my knowledge and expertise. </p>
   My research interests lie in <strong>Efficient AI</strong>, which entails exploring training- or data-efficient approaches to make AI more accessible and sustainable. Some of my research areas include Self-Supervised Learning, Federated Learning, Generative AI, and Multimodal Learning.
   <!-- I am a Research Scientist at the Amazon Transcribe Team of AWS AI Labs. Previsouly, I was Research Scientist at NAVER AI Lab in 2021-2022. I also graduated with my PhD in February 2021 from the Graduate School of Knowledge Service Engineering (currently, Data Science) at KAIST and worked as a research intern at Google Research, where I was fortunate to work with two supervisors, <a href="https://scholar.google.com/citations?user=h9mbv9MAAAAJ&hl=en&oi=ao"><font color="#000080">Prof. Jae-Gil Lee</font></a> and <a href="https://scholar.google.com/citations?hl=en&user=p9-ohHsAAAAJ"><font color="#000080">Prof. Ming-Hsuan Yang</font></a>. My current research interests lie in exploring the cutting-edge technologies for future AI (e.g., Data Robust/Efficient Learning, Transformers, Large Language Models) and improving the performance of AI systems under real-world scenarios related to data scale and quality. -->


   <a id="news" class="news"></a><span class="section">News</span> 
   <p class="news">
    <strong>Jun. 2023:</strong> &#x1F680 Two poster sessions at CVPR 2023 in Vancouver.
    </p>
    <p class="news">
     <strong>May 2023:</strong> &#x1F38A A Paper on 'Respiratory Sound Classification' accepted at INTERSPEECH 2023.
    </p>     
    <p class="news">
     <strong>Feb. 2023:</strong> &#x1F38A Two Papers on 'Self-Supervised Learning' and 'Federated Active Learning' accepted at CVPR 2023.
    </p>     
    <p class="news">
     <strong>Fed. 2023:</strong>  &#x1F680 Oral presentation at AAAI 2023 in Washington, DC.
    </p>

    <p>&nbsp;</p>

   <a id="education" class="education"></a><span class="section">Education</span> 

   <li style="line-height:160%;"> Ph.D. student in Graduate School of AI, KAIST. Advised by Prof. <a href="https://scholar.google.com/citations?user=X_IAjb8AAAAJ&hl=en"><font color="#000080">Se-Young Yun</font></a>. <em>Present</em> </li> 
   <li style="line-height:160%;">  M.S. in Industrial and Systems Engineering, KAIST. Advised by Prof. Se-Young Yun. <em>Feb. 2021</em> </li> 
   <li style="line-height:160%;">  B.S. in Industrial and Systems Engineering. <em>Feb. 2019</em> </li> 
	

   <p>&nbsp;</p>

    <!-- Publication session -->
    <a id="publications" class="anchor"></a><span class="section">Publications <a href="https://scholar.google.com/citations?user=T5rHY14AAAAJ&hl=en">  Google Scholar </a> </span>
    The asterisk<strong>*</strong>  and <u>underline</u> indicate the 1st co-author and corresponding author, respectively. </br> </br>
    <table border="0" width="90%" class="paper">
	
      <tbody><font size="4.5px"><strong>2023</strong></font>

        <tr>
          <td>
            <img src="./images/2023_free.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            <strong>S. Bae</strong>*, J. Ko*, <u>H. Song</u>, <u>S-Y. Yun</u>.  <strong>Fast and Robust Early-Exiting Framework for Autoregressive Language Models with Synchronized Parallel Decoding</strong>. <em>Preprint</em> 2023.
          </td>
        </tr>   

        <tr>
          <td>
            <img src="./images/2023_patchmix.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td bgcolor="#e9eaed">
            <strong>S. Bae</strong>*, J. Kim*, W. Cho, H. Baek, S. Son, B. Lee, C. Ha, K. Tae, <u>S. Kim</u>, <u>S-Y. Yun</u>.   <strong>Patch-Mix Contrastive Learning with Audio Spectrogram Transformer on Respiratory Sound Classification</strong>. <em>Conference of the International Speech Communication Association </em>  (INTERSPEECH) 2023.
            [<a href="https://arxiv.org/pdf/2305.14032.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/raymin0223/patch-mix_contrastive_learning"><font color="#000080">code</font></a>]
          </td>
        </tr>   

        <tr>
          <td>
            <img src="./images/2023_openset.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            S. Kim*, <strong>S. Bae</strong>*, <u>S-Y. Yun</u>.   <strong>Coreset Sampling from Open-Set for Fine-Grained Self-Supervised Learning</strong>. <em>International Conference on Computer Vision and Pattern Recognition </em>  (CVPR) 2023.
            [<a href="https://arxiv.org/pdf/2303.11101.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/sungnyun/openssl-simcore"><font color="#000080">code</font></a>]
          </td>
        </tr>   

        <tr>
        <td>
            <img src="./images/2023_logo.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td bgcolor="#e9eaed">
            S. Kim*, <strong>S. Bae</strong>*, <u>H. Song</u>, <u>S-Y. Yun</u>.  <strong>Re-thinking Federated Active Learning based on Inter-class Diversity</strong>. <em>International Conference on Computer Vision and Pattern Recognition </em> (CVPR) 2023. 
            [<a href="https://arxiv.org/pdf/2303.12317.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/raymin0223/LoGo"><font color="#000080">code</font></a>]
          </td>
        </tr>    

        <tr>
        <td>
            <img src="./images/2023_selfcon.png" class="PaperThumbnail" width="120" height="60">
          </td>
          <td>
            <strong>S. Bae</strong>*, S. Kim*, J. Ko, G. Lee, S. Noh, <u>S-Y. Yun</u>.  <strong>Self-Contrastive Learning: Single-viewed Supervised Contrastive Framework using Sub-network</strong>. <em>The Association for the Advancement of Artificial Intelligence </em> (AAAI) 2023. <span class="oral">Oral Presentation.</span>
            [<a href="https://arxiv.org/pdf/2106.15499.pdf"><font color="#000080">pdf</font></a>]
            [<a href="https://github.com/raymin0223/self-contrastive-learning"><font color="#000080">code</font></a>]
          </td>
        </tr>  
	  
	  
	</tbody></table></br>
	<font size="4.5px"><strong>2022</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
	   
      <tr>
        <td>
          <img src="./images/2022_fedntd.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td bgcolor="#e9eaed">
          G. Lee*, M. Jeong*, Y. Shin, <strong>S. Bae</strong>, <u>S-Y. Yun</u>. <strong>Preservation of Global Knowledge by Not-True Distillation in Federated Learning</strong>. <em>Neural Information Processing Systems </em> (NeurIPS) 2022. 
		  [<a href="https://arxiv.org/pdf/2106.03097.pdf"><font color="#000080">pdf</font></a>]
		  [<a href="https://github.com/Lee-Gihun/FedNTD"><font color="#000080">code</font></a>]
		  </td>
      </tr>
	  	  

      <tr>
        <td>
          <img src="./images/2022_openset.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td>
          S. Kim*, <strong>S. Bae</strong>*, <u>S-Y. Yun</u>. <strong>Coreset Sampling from Open-Set for Fine-Grained Self-Supervised Learning</strong>. <em>Neural Information Processing Systems SSLTheoryPractice Workshop </em> (NeurIPSW) 2022. 
		  [<a href="https://sslneurips22.github.io/paper_pdfs/paper_28.pdf"><font color="#000080">pdf</font></a>]
		  </td>
      </tr>

      <tr>
        <td>
          <img src="./images/2022_lg_fal.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td bgcolor="#e9eaed">
          S. Kim*, <strong>S. Bae</strong>*, <u>H. Song</u>, <u>S-Y. Yun</u>.  <strong>LG-FAL: Federated Active Learning Strategy using Local and Global Models</strong>. <em>International Conference on Machine Learning ReALML Workshop </em> (ICMLW) 2022. 
          [<a href="https://realworldml.github.io/files/cr/paper46.pdf"><font color="#000080">pdf</font></a>]
        </td>
      </tr>  
      
	</tbody></table></br>
	<font size="4.5px"><strong>2020</strong></font>
	<table border="0" width="90%" class="paper"><tbody>
	  
        <tr>
        <td>
          <img src="./images/2020_mixco.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td>
          S. Kim*, G. Lee*, <strong>S. Bae</strong>*, <u>S-Y. Yun</u>.  <strong>MixCo: Mix-up Contrastive Learning for Visual Representation</strong>. <em>Neural Information Processing Systems SSLTheoryPractice Workshop </em> (NeurIPSW) 2020. 
          [<a href="https://arxiv.org/pdf/2010.06300.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/Lee-Gihun/MixCo-Mixup-Contrast"><font color="#000080">code</font></a>]
        </td>
      </tr>   

      <tr>
        <td>
          <img src="./images/2020_mabfl.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td bgcolor="#e9eaed">
          T. Kim*, <strong>S. Bae</strong>*, J. Lee, <u>S-Y. Yun</u>.  <strong>Accurate and Fast Federated Learning via Combinatorial Multi-Armed Bandits</strong>. <em>Preprint </em> 2020. 
          [<a href="https://arxiv.org/pdf/2012.03270.pdf"><font color="#000080">pdf</font></a>]
        </td>
      </tr>   

        <tr>
        <td>
          <img src="./images/2020_sipa.png" class="PaperThumbnail" width="120" height="60">
        </td>
        <td>
          G. Lee*, <strong>S. Bae</strong>*, J. Oh, <u>S-Y. Yun</u>.  <strong>SIPA: A Simple Framework for Efficient Networks</strong>. <em>IEEE International Conference on Data Mining Workshop </em> (ICDMW) 2020. 
          [<a href="https://arxiv.org/pdf/2004.14476.pdf"><font color="#000080">pdf</font></a>]
          [<a href="https://github.com/Lee-Gihun/MicroNet_OSI-AI"><font color="#000080">code</font></a>]
        </td>
      </tr>   
	  
    </tbody></table>

    <p>&nbsp;</p>

	 
    <a id="projects" class="anchor"></a><span class="section">Projects</span>

    
    <li style="line-height:160%;"> [<strong>NIER</strong>] Short-term Prediction of Particulate Matter via Artificial Intelligence. <span class="oral">Project Manager</span>. <em>2023-Present</em>  </li> 
    <li style="line-height:160%;">  [<strong>KT</strong>] Neural Architecture Search for Detecting Communication Network Failure. <span class="oral">Project Manager</span>. <em>2022-2023</em>   </li> 
    <li style="line-height:160%;">  [<strong>ETRI</strong>] Lightweight Edge Device Technology via Federated Learning. <span class="oral">Project Manager</span>. <em>2021-2022</em>  </li> 
    <li style="line-height:160%;"> [<strong>SK Hynix</strong>] Semantic Segmentation to Detect Errors in Wafer Process. <em>2021</em>  </li>  
    <li style="line-height:160%;"> [<strong>ETRI</strong>] Data-efficient Unsupervised Representation Learning. <em>2020</em>  </li> 
    <li style="line-height:160%;"> [<strong>Hankook Tire and Technology</strong>] Compound Prediction with Artificial Intelligence and Auto-ML. <em>2019-2020</em>  </li>
    <li style="line-height:160%;"> [<strong>ETRI</strong>] Model Compression for Big Data Ddge Analysis. <em>2019</em>  </li>

    <p>&nbsp;</p>

	 
    <a id="services" class="anchor"></a><span class="section">Services</span>
    <li style="line-height:160%;">  Research Collaboration with NAVER AI, advised by Hwanjun Song. <em>2022-2023</em> </li>
    <li style="line-height:160%;">  Research Internship at Kakao Recommendation Team. <em>2018-2019</em> </li>
    <li style="line-height:160%;">   Research Internship at Optimization and Statistical Inference Lab, KAIST. <em>2018</em> </li>
    <li style="line-height:160%;">  Research Internship at Human Factors and Ergonomics Lab, KAIST. <em>2017-2018</em> </li>
    <li style="line-height:160%;">   Exchange Student at  Linköping University, Sweden. <em>2017</em>    </li>

    
    <p>&nbsp;</p>

	 
    <a id="adwards" class="anchor"></a><span class="section">Awards</span>
    <li style="line-height:160%;">  Two Best Presentation Awards from Korea Computing Congress (KCC). <em>2022</em> </li>
    <li style="line-height:160%;">  Best Paper Award (5th Place) from Korean AI Association and LG AI Research (JKAIA).  <em>2021</em></li>
    <li style="line-height:160%;">    <a href="https://micronet-challenge.github.io"><font color="#000080">MicroNet Challenge</font></a> 4th Place at NeurIPS Workshop. <em>2019</em> </li>
    <li style="line-height:160%;"> Dean's List (Top 3%) at Faculty of Engineering Department in KAIST. <em>2017</em> </li>
    
    <p>&nbsp;</p>

	 
    <a id="patents" class="anchor"></a><span class="section">Patents</span>
    <li style="line-height:130%;"> Toward Enhanced Representation for Federated Re-Identification by Not-True Self Knowledge Distillation. S-Y. Yun, S. Kim, W. Chung, <strong>S. Bae</strong>. <em>Korea Patent Application</em>. </li>
    <li style="line-height:130%;"> Federated Learning System for Performing Individual Data Customized Federated Learning, Method for Federated Learning, and Client Aratus for Performing Same. J. Oh, S. Kim, S-Y. Yun, <strong>S. Bae</strong>, J. SHin, S. Kim, W. Chung. <em>US and Korea Patent Application</em>. </li>
    <li style="line-height:130%;"> System, Method, Computer-Readable Storage Medium and Computer Program for Federated Learning of Local Model based on Learning Direction of Global Model. G. Lee, M. Jeong, S-Y. Yun, <strong>S. Bae</strong>, J. Ahn, S. Kim, W. Chung. <em>US and Korea Patent Application</em>.     </li>	
    
    </br>  

	 
    <!-- <a id="adwards" class="anchor"></a><span class="section">Awards and Patents</span>
    
    <p class="adwards"></br><strong> Awards </strong></br> 
      <li style="line-height:160%;">   Two Best Presentation Awards from Korea Computing Congress (KCC). <em>2022</em> </li>
      <li style="line-height:160%;">   Best Paper Award (5th Place) from Korean AI Association and LG AI Research (JKAIA).  <em>2021</em></li>
      <li style="line-height:160%;">   <a href="https://micronet-challenge.github.io"><font color="#000080">MicroNet Challenge</font></a> 4th Place at NeurIPS Workshop. <em>2019</em> </li>
      <li style="line-height:160%;">   Dean's List (Top 3%) at Faculty of Engineering Department in KAIST. <em>2017</em> </li>
   
    <p class="adwards"></br><strong> Patents </strong></br> 
	
      <li style="line-height:130%;">  Toward Enhanced Representation for Federated Re-Identification by Not-True Self Knowledge Distillation. S-Y. Yun, S. Kim, W. Chung, <strong>S. Bae</strong>. <em>Korea Patent Application</em>. </li>
      <li style="line-height:130%;">   Federated Learning System for Performing Individual Data Customized Federated Learning, Method for Federated Learning, and Client Aratus for Performing Same. J. Oh, S. Kim, S-Y. Yun, <strong>S. Bae</strong>, J. SHin, S. Kim, W. Chung. <em>US and Korea Patent Application</em>. </li>
      <li style="line-height:130%;">  System, Method, Computer-Readable Storage Medium and Computer Program for Federated Learning of Local Model based on Learning Direction of Global Model. G. Lee, M. Jeong, S-Y. Yun, <strong>S. Bae</strong>, J. Ahn, S. Kim, W. Chung. <em>US and Korea Patent Application</em>.     </li>	 -->

<!-- <a id="students" class="anchor"></a><span class="section">Research Advisors </span>

<p> <font color="#444444" face="Arial" size="2"> I have been fortunate to work with many gifted advisors:</font> </p>
  <ul>
  <font color="#444444" face="Arial" size="2">    
  <li> <a href="https://songhwanjun.github.io"> Hwanjun Song </a> (KAIST → NAVER AI → AWS AI), 2022-2023  </li>
  </font>
  </ul> -->

  <p><font color="#444444" face="Arial" size="2">&copy 2023 Sangmin Bae Thanks <a href="https://songhwanjun.github.io"><font color="#000080">Dr. Hwanjun Song</font></a> for the template. </font></p>

  </div>
  <script>
    var thumbnails = document.getElementsByClassName("PaperThumbnail");
    var i;
    for (i = 0; i < thumbnails.length; i++) {
      thumbnails[i].width = "120"
    }
  </script>  


</body></html>
